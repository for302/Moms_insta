use crate::models::{CharacterPersona, ContentGenerationRequest, ContentPlanItem};
use crate::services::anthropic::AnthropicService;
use crate::services::google::GoogleService;
use crate::services::openai::OpenAIService;
use uuid::Uuid;

/// Create a character persona name from keyword
fn extract_character_name(keyword: &str) -> String {
    let cleaned: String = keyword
        .chars()
        .filter(|c| c.is_alphabetic() || (*c >= '\u{AC00}' && *c <= '\u{D7A3}'))
        .collect();

    // For Korean keywords, take first 2 characters
    // For English keywords, take first 4 characters
    if cleaned.chars().any(|c| c >= '\u{AC00}' && c <= '\u{D7A3}') {
        cleaned.chars().take(2).collect()
    } else {
        cleaned.chars().take(4).collect()
    }
}

#[tauri::command]
pub async fn create_persona(keyword: String) -> Result<CharacterPersona, String> {
    if keyword.trim().is_empty() {
        return Err("í‚¤ì›Œë“œë¥¼ ìž…ë ¥í•´ì£¼ì„¸ìš”.".to_string());
    }

    let name = extract_character_name(&keyword);

    Ok(CharacterPersona {
        name: name.clone(),
        description: format!("{}ì˜ ë¹„ë°€ì„ ì—°êµ¬í•˜ëŠ” ê·€ì—¬ìš´ ìºë¦­í„°", keyword),
        personality_traits: vec![
            "í˜¸ê¸°ì‹¬ ë§Žì€".to_string(),
            "ì¹œê·¼í•œ".to_string(),
            "ì „ë¬¸ì ì¸".to_string(),
            "ë”°ëœ»í•œ".to_string(),
        ],
    })
}

#[tauri::command]
pub async fn generate_content_plan(
    request: ContentGenerationRequest,
) -> Result<Vec<ContentPlanItem>, String> {
    if request.keyword.trim().is_empty() {
        return Err("í‚¤ì›Œë“œë¥¼ ìž…ë ¥í•´ì£¼ì„¸ìš”.".to_string());
    }

    let api_key = request
        .api_key
        .clone()
        .ok_or_else(|| "API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.".to_string())?;

    let provider = request.llm_provider.clone().unwrap_or_else(|| "openai".to_string());
    let character_name = extract_character_name(&request.keyword);
    let count = request.count.min(20).max(1);

    // Create content generation prompt
    let system_prompt = format!(
        r#"ë‹¹ì‹ ì€ ì¸ìŠ¤íƒ€ê·¸ëž¨ ë·°í‹° ì½˜í…ì¸  ê¸°íš ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.
í™”ìž¥í’ˆ ì„±ë¶„ì— ëŒ€í•œ êµìœ¡ì ì¸ ìºëŸ¬ì…€ ì½˜í…ì¸ ë¥¼ ê¸°íší•©ë‹ˆë‹¤.

íƒ€ê²Ÿ: ìœ¡ì•„ë§˜, ì˜ˆë¹„ë§˜ (ì„±ë¶„ì— ë¯¼ê°í•œ ì‚¬ìš©ìž)
ìºë¦­í„°: {} (ì„±ë¶„ì„ ì˜ì¸í™”í•œ ê·€ì—¬ìš´ ìºë¦­í„°)
í˜•ì‹: {}ì˜ ì—°êµ¬ì¼ì§€

ê° ì½˜í…ì¸ ëŠ” ë‹¤ìŒ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ìž‘ì„±í•˜ì„¸ìš”:
[
  {{
    "title": "ë§¤ë ¥ì ì¸ ì œëª©",
    "content": "50ìž ë‚´ì™¸ì˜ í•µì‹¬ ë‚´ìš© (ì´ëª¨ì§€ ì‚¬ìš© ê°€ëŠ¥)",
    "image_concept": "ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ ìƒì„¸í•œ ì»¨ì…‰ ì„¤ëª…"
  }},
  ...
]

ì£¼ì˜ì‚¬í•­:
- ê³¼í•™ì  ê·¼ê±°ì— ê¸°ë°˜í•˜ë˜ ì‰½ê²Œ ì„¤ëª…
- ìž„ì‚°ë¶€/ì•„ê¸°ì—ê²Œ ì•ˆì „í•œ ì •ë³´ ì¤‘ì‹¬
- ê¸ì •ì ì´ê³  ë”°ëœ»í•œ í†¤
- JSON ë°°ì—´ë§Œ ì¶œë ¥í•˜ì„¸ìš”"#,
        character_name, character_name
    );

    let prompt = format!(
        "'{}'ì— ëŒ€í•œ {}ê°œì˜ ì¸ìŠ¤íƒ€ê·¸ëž¨ ìºëŸ¬ì…€ ì½˜í…ì¸ ë¥¼ ê¸°íší•´ì£¼ì„¸ìš”.\n\nì¶”ê°€ ì •ë³´:\n{}",
        request.keyword,
        count,
        request.research_data.clone().unwrap_or_default()
    );

    // Call LLM
    let response = match provider.as_str() {
        "anthropic" => {
            let service = AnthropicService::new(&api_key);
            service.generate_text(&prompt, Some(&system_prompt)).await?
        }
        "google" => {
            let service = GoogleService::new(&api_key);
            service.generate_text(&prompt, Some(&system_prompt)).await?
        }
        _ => {
            let service = OpenAIService::new(&api_key);
            service.generate_text(&prompt, Some(&system_prompt)).await?
        }
    };

    // Parse response
    let items = parse_content_plan(&response, &character_name, &request.keyword)?;
    Ok(items)
}

fn parse_content_plan(
    response: &str,
    character_name: &str,
    keyword: &str,
) -> Result<Vec<ContentPlanItem>, String> {
    // Extract JSON array from response
    let json_str = extract_json_array(response);

    #[derive(serde::Deserialize)]
    struct LLMContent {
        title: String,
        content: String,
        image_concept: String,
    }

    let parsed: Vec<LLMContent> = serde_json::from_str(&json_str).unwrap_or_else(|_| {
        // Fallback to default content if parsing fails
        generate_fallback_content(keyword, 10)
            .into_iter()
            .map(|f| LLMContent {
                title: f.title,
                content: f.content,
                image_concept: f.image_concept,
            })
            .collect()
    });

    let items: Vec<ContentPlanItem> = parsed
        .into_iter()
        .enumerate()
        .map(|(i, c)| ContentPlanItem {
            id: Uuid::new_v4().to_string(),
            title: c.title,
            character_name: character_name.to_string(),
            journal_number: (i + 1) as u32,
            content: c.content,
            image_concept: c.image_concept,
            status: "pending".to_string(),
        })
        .collect();

    Ok(items)
}

fn extract_json_array(text: &str) -> String {
    // Find JSON array in the response
    if let Some(start) = text.find('[') {
        if let Some(end) = text.rfind(']') {
            return text[start..=end].to_string();
        }
    }
    "[]".to_string()
}

#[derive(serde::Serialize, serde::Deserialize)]
struct FallbackContent {
    title: String,
    content: String,
    image_concept: String,
}

fn generate_fallback_content(keyword: &str, count: usize) -> Vec<FallbackContent> {
    let topics = vec![
        ("ê¸°ì´ˆ íš¨ëŠ¥", "í”¼ë¶€ì— ë¯¸ì¹˜ëŠ” ê¸°ë³¸ì ì¸ íš¨ê³¼ë¥¼ ì•Œì•„ë´ìš” âœ¨"),
        ("ë³´ìŠµ ë©”ì»¤ë‹ˆì¦˜", "í”¼ë¶€ ì† ìˆ˜ë¶„ì„ ì–´ë–»ê²Œ ì§€ì¼œì¤„ê¹Œìš”? ðŸ’§"),
        ("ìž¥ë²½ ê°•í™”", "í”¼ë¶€ ìž¥ë²½ì„ íŠ¼íŠ¼í•˜ê²Œ ë§Œë“œëŠ” ë¹„ê²° ðŸ›¡ï¸"),
        ("ì§„ì • íš¨ê³¼", "ë¯¼ê°í•´ì§„ í”¼ë¶€ë¥¼ ë‹¬ëž˜ì£¼ëŠ” ë°©ë²• ðŸŒ¿"),
        ("ì•„ê¸° í”¼ë¶€", "ì—°ì•½í•œ ì•„ê¸° í”¼ë¶€ì—ë„ ì•ˆì „í•´ìš” ðŸ‘¶"),
        ("ìž„ì‚°ë¶€ ì•ˆì „ì„±", "ìž„ì‚°ë¶€ë„ ì•ˆì‹¬í•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìžˆì–´ìš” ðŸ¤°"),
        ("EWG ë“±ê¸‰", "ì•ˆì „ì„± ë“±ê¸‰ì´ ì˜ë¯¸í•˜ëŠ” ê²ƒ ðŸ“Š"),
        ("ì ì • ë†ë„", "ì–¼ë§ˆë‚˜ ë“¤ì–´ìžˆìœ¼ë©´ íš¨ê³¼ì ì¼ê¹Œìš”? ðŸ§ª"),
        ("í•¨ê»˜ ì“°ë©´ ì¢‹ì€ ì„±ë¶„", "ì‹œë„ˆì§€ë¥¼ ë‚´ëŠ” ì¡°í•© ðŸ’ª"),
        ("ì œí˜•ë³„ íŠ¹ì§•", "í¬ë¦¼, ì„¸ëŸ¼, ì—ì„¼ìŠ¤ì˜ ì°¨ì´ ðŸ§´"),
    ];

    topics
        .into_iter()
        .take(count)
        .map(|(title, content)| FallbackContent {
            title: format!("{} - {}", keyword, title),
            content: content.to_string(),
            image_concept: format!(
                "ê·€ì—¬ìš´ ìºë¦­í„°ê°€ ì—°êµ¬ì‹¤ì—ì„œ {}ì„(ë¥¼) ë¶„ì„í•˜ë©° {} í¬ì¸íŠ¸ë¥¼ ì„¤ëª…í•˜ëŠ” ì¼ëŸ¬ìŠ¤íŠ¸",
                keyword, title
            ),
        })
        .collect()
}

#[tauri::command]
pub async fn translate_to_korean(
    text: String,
    api_key: String,
    provider: String,
) -> Result<String, String> {
    if text.trim().is_empty() {
        return Ok(text);
    }

    let system_prompt = "You are a professional translator. Translate the given English text to Korean. Only output the translated text, nothing else. Keep the translation natural and accurate.";
    let prompt = format!("Translate the following text to Korean:\n\n{}", text);

    let response = match provider.as_str() {
        "anthropic" => {
            let service = AnthropicService::new(&api_key);
            service.generate_text(&prompt, Some(system_prompt)).await?
        }
        "google" => {
            let service = GoogleService::new(&api_key);
            service.generate_text(&prompt, Some(system_prompt)).await?
        }
        _ => {
            let service = OpenAIService::new(&api_key);
            service.generate_text(&prompt, Some(system_prompt)).await?
        }
    };

    Ok(response.trim().to_string())
}
